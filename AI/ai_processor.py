import base64
import requests
import os
import re
import numpy as np
import matplotlib.pyplot as plt
from openai import OpenAI
from AI.template_matcher import match_template  # í…œí”Œë¦¿ ë§¤ì¹­ í•¨ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or "YOUR_KEY"
MATHPIX_APP_ID = os.getenv("MATHPIX_APP_ID") or "YOUR_ID"
MATHPIX_APP_KEY = os.getenv("MATHPIX_APP_KEY") or "YOUR_KEY"

client = OpenAI(api_key=OPENAI_API_KEY)

def process_image(image_path: str, grade: str) -> str:
    with open(image_path, "rb") as image_file:
        img_base64 = base64.b64encode(image_file.read()).decode()

    ocr_response = requests.post("https://api.mathpix.com/v3/text", json={
        "src": f"data:image/jpeg;base64,{img_base64}",
        "formats": ["text"],
        "ocr": ["math", "text"],
        "math_inline_delimiters": ["$", "$"],
        "skip_recrop": True
    }, headers={
        "app_id": MATHPIX_APP_ID,
        "app_key": MATHPIX_APP_KEY,
        "Content-type": "application/json"
    })

    text_raw = ocr_response.json().get("text", "").replace("$", "").strip()
    if not text_raw:
        return "â— OCR ì‹¤íŒ¨: ìˆ˜ì‹ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # í…œí”Œë¦¿ ë§¤ì¹­ ì‹œë„
    matched_template = match_template(text_raw, grade)

    if matched_template:
        print(f"âœ… í…œí”Œë¦¿ ë§¤ì¹­ë¨: {matched_template.get('name', 'ì´ë¦„ ì—†ìŒ')}")
        steps = matched_template.get("solution_steps", [])
        step_text = "\n".join([f"{i+1}. {s}" for i, s in enumerate(steps)])
        explain_prompt = f"""
ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ ë°˜ë“œì‹œ ì•„ë˜ì˜ 5ë‹¨ê³„ í’€ì´ íë¦„ì„ ê·¸ëŒ€ë¡œ ë”°ë¥´ë©°, ê° ë‹¨ê³„ ë²ˆí˜¸ì™€ ì„¤ëª… ë¬¸ì¥ì€ ì ˆëŒ€ ìˆ˜ì •í•˜ì§€ ë§ê³  ì‚¬ìš©í•´.
ê° ë‹¨ê³„ ì•„ë˜ì— í•„ìš”í•œ ê³„ì‚°ê³¼ í•´ì„¤ë§Œ ì¶”ê°€í•´. êµ¬ì¡°ë‚˜ ë¬¸ì¥ ìˆ˜ì • ì—†ì´ ê³ ì •ëœ í‹€ì„ ì§€ì¼œì•¼ í•´.

í’€ì´ ìˆœì„œ:
{step_text}

ë¬¸ì œ:
{text_raw}

ë§ˆì§€ë§‰ ì¤„ì—ëŠ” 'ì •ë‹µ: (ìˆ«ì)' í˜•íƒœë¡œ ì¨ì¤˜.
"""
    else:
        print("âš ï¸ í…œí”Œë¦¿ ë§¤ì¹­ ì•ˆë¨. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©.")
        explain_prompt = f"""
ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ 5ë‹¨ê³„ë¡œ ë‚˜ëˆ  ìì„¸íˆ í’€ì–´ì¤˜. Latex ë§ê³  ì¼ë°˜ ìˆ˜ì‹ê³¼ ì„¤ëª…ì„ ì„ì–´ì„œ, ê³ ë“±í•™ìƒì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¨ì¤˜.
ë§ˆì§€ë§‰ ì¤„ì— 'ì •ë‹µ: (ìˆ«ì)' í˜•íƒœë¡œ ì¨ì¤˜.
ë¬¸ì œ:
{text_raw}
"""

    print(" ìµœì¢… í”„ë¡¬í”„íŠ¸:")
    print(explain_prompt)

    solve_response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": explain_prompt}]
    )
    explanation = solve_response.choices[0].message.content.strip()

    graph_prompt = f"""
ë‹¤ìŒ ìˆ˜í•™ í•¨ìˆ˜(ë˜ëŠ” êµ¬ê°„ë³„ í•¨ìˆ˜)ì˜ ê·¸ë˜í”„ë¥¼ matplotlib ì½”ë“œë¡œ ê·¸ë ¤ì¤˜.
ì¡°ê±´:
- np.linspace ì‚¬ìš©
- ì¡°ê±´ë¶€ í•¨ìˆ˜ë©´ êµ¬ê°„ì„ ë‚˜ëˆ  ê°ê° plot
- xì¶•ê³¼ yì¶• ë¼ë²¨ ì¶”ê°€
- plt.savefig('graph_output.png') ìœ¼ë¡œ ì €ì¥
- plt.show() í•˜ì§€ ë§ê³  ì €ì¥ë§Œ
- ì½”ë“œ ì™¸ í…ìŠ¤íŠ¸ ì—†ì´ ìˆœìˆ˜ Python ì½”ë“œë§Œ ì¤˜
ìˆ˜ì‹:
{text_raw}
"""

    graph_response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": graph_prompt}]
    )

    code_block = re.findall(r"```python(.*?)```", graph_response.choices[0].message.content, re.DOTALL)
    if code_block:
        try:
            exec(code_block[0], {"np": np, "plt": plt})
        except Exception as e:
            explanation += f"\n\n[âš ï¸ ê·¸ë˜í”„ ì½”ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {e}]"

    result_output = (
        f"ğŸ“„ OCR ì¸ì‹ëœ ë¬¸ì œ:\n{text_raw}\n\n"
        f" ë¬¸ì œ í’€ì´:\n{explanation}"
    )
    return result_output
